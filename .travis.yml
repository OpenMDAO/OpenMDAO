branches:
  only:
  - master
  - auto_ivc

group: deprecated-2017Q4

filter_secrets: false

os:
- linux

language: generic

env:
  matrix:
    # latest versions
    - PY=3   NUMPY=1    SCIPY=1   PYOPTSPARSE=v2.1.5 SNOPT=7.7 PETSc=3
    # baseline versions
    - PY=3.8 NUMPY=1.18 SCIPY=1.4 PYOPTSPARSE=v2.1.5 SNOPT=7.7 PETSc=3.12 UPLOAD_DOCS=1
    # older versions
    - PY=3.7 NUMPY=1.17 SCIPY=1.3 PYOPTSPARSE=v2.1.5 SNOPT=7.7
    - PY=3.6 NUMPY=1.16 SCIPY=1.2 PYOPTSPARSE=v1.2   SNOPT=7.2 PETSc=3.10.2

git:
  depth: 99999

addons:
  apt:
    update: true
    sources:
    - ubuntu-toolchain-r-test
    packages:
    - gfortran
    - gcc
    - g++
    - liblapack-dev
    ssh_known_hosts:
    - web543.webfaction.com


notifications:
  slack:
    secure: Dd+tpZkz48Q47Y+PtdL4b+KAs55PsvWjt9ybhip6xljhA5kVsba9oZS+KsAC8RLWSzVJLOSjz3Cu3MsRym4sTd/g4Pbqyh0ldK2Xnl+n2JOgpPFSXtFuH4Ln3uWB6kYtUK6+aGIC8qhbvEt8tukTBT0RduEmdRyVIZ3oN7YjETPSZXvujeiUFLssfpZW2mqoA/tIgJHFSlySAp6J5694t2Z/p8sHOrK8G/Nm+qlk4xqXHvJ3xablcSBG4BZCrpqmMMdTLXBt2E2K9Rc1P2ZBIrSHVWfSLx+4n79U2385+og7miN1Zuf3gY3YuGKIwnBTtEzTu20905idkr4QdKELCBEcU4azdznwjvUkXWkiFAJII9UELTluSQmZX602zWk4AgJNeHxhN3EbBSMezfYVZjprhlAlwnZZv6t4qAkvuzb7KOA4s679xWzWOBOn1wkynfIF8A66APqssveyz/PvZHSjnHQoLgMU+kwzoX759o0Z/HuRlhCcjv0W9DWxU2bFNi/zVh9YyvR8fG15biGthzOyuf+CHjxohw+J6M+YdR1RIf1g/60nGUPHx4j4SN3kEFPmEDxzZT/f349gvaZGOmKXBi0wH8iY/i9RinM9LJB4t6chj2MkKwUA26bYaVaIO6FYPfE7r+tTG6OXdck4voCs/s4aa9VKEX97yhh0i9g=

before_install:
# When building master (e.g. after a merge), we will create a fresh env as a thorough test.
# For other builds (e.g. pull requests), try to use cached env for faster testing.
# Need to check for existence of files to determine if cache exists.
# If the dir doesn't exist, but is slated to be cached later,
# Travis unhelpfully creates it, which then causes "dir already exists"
# errors when you go to actually install the thing, so we must non-intuitively
# delete the file before re-creating it later.
- if  [ "$TRAVIS_REPO_SLUG" = "OpenMDAO/OpenMDAO" ] && [ "$TRAVIS_BRANCH" = "master" ] && [ "$TRAVIS_PULL_REQUEST" = "false" ]; then
    echo "building master";
    MASTER_BUILD=1;
    rm -rf $HOME/miniconda;
  elif [ -d $HOME/miniconda/envs/PY$PY ]; then
    echo "cached miniconda environment found";
    CACHED_ENV=1;
  else
    echo "cached miniconda environment not found";
    rm -rf $HOME/miniconda;
  fi

install:
# get key decrypted, placed, chmodded, and added for passwordless access to WebFaction
- if [ "$encrypted_74d70a284b7d_key" ]; then
    openssl aes-256-cbc -K $encrypted_74d70a284b7d_key -iv $encrypted_74d70a284b7d_iv -in travis_deploy_rsa.enc -out /tmp/travis_deploy_rsa -d;
    eval "$(ssh-agent -s)";
    chmod 600 /tmp/travis_deploy_rsa;
    ssh-add /tmp/travis_deploy_rsa;
    echo -e "Host web543.webfaction.com\n\tStrictHostKeyChecking no\n" >> ~/.ssh/config;
  else
    echo "KEY NOT FOUND";
  fi

# build Python environment
- |
  echo ">>> Building python environment";
  echo " >> Installing conda";
  echo "  > Downloading miniconda";
  wget "https://repo.anaconda.com/miniconda/Miniconda${PY:0:1}-latest-Linux-x86_64.sh" -O miniconda.sh;
  chmod +x miniconda.sh;
  echo "  > Installing miniconda";
  ./miniconda.sh -b  -p $HOME/miniconda;
  export PATH=$HOME/miniconda/bin:$PATH;

  echo " >> Creating conda environment";
  conda create --yes -n PY$PY python=$PY numpy=$NUMPY scipy=$SCIPY cython swig;
  source $HOME/miniconda/bin/activate PY$PY;

  pip install --upgrade pip;

  if [ "$PETSc" ]; then
    echo " >> Installing PETSc";
    conda install -c anaconda mpi4py --yes;
    conda install -c conda-forge petsc=$PETSc petsc4py --yes;
  fi

  if [ "$PYOPTSPARSE" ]; then
    echo " >> Installing pyOptSparse";
    git clone -q https://github.com/OpenMDAO/build_pyoptsparse;

    cd build_pyoptsparse;
    chmod 755 ./build_pyoptsparse.sh;

    if [ "$PETSc" ]; then
      PAROPT=-a;
    fi

    if [ "$SNOPT" == "7.7" ] && [ "$SNOPT_LOCATION_77" ]; then
      echo "  > Secure copying SNOPT 7.7 over SSH";
      mkdir SNOPT;
      scp -qr "$SNOPT_LOCATION_77" SNOPT;
      ./build_pyoptsparse.sh -b "$PYOPTSPARSE" -s SNOPT/src $PAROPT;

    elif [ "$SNOPT" == "7.2" ] && [ "$SNOPT_LOCATION_72" ]; then
      echo "  > Secure copying SNOPT 7.2 over SSH";
      mkdir SNOPT;
      scp -qr "$SNOPT_LOCATION_72" SNOPT;
      ./build_pyoptsparse.sh -b "$PYOPTSPARSE" -s SNOPT/source $PAROPT;

    else
      if [ "$SNOPT" ]; then
        echo "SNOPT version $SNOPT was requested but source is not available";
      fi
      ./build_pyoptsparse.sh -b "$PYOPTSPARSE" $PAROPT;
    fi

    cd ..;
  fi

  echo " >> Installing optional packages for test coverage";
  pip install psutil objgraph git+https://github.com/mdolab/pyxdsm;

# install OpenMDAO and its development and documentation dependencies
# NOTE: not using -e on purpose here, to catch packaging errors
- echo ">>> Installing OpenMDAO";
  pip install .[all];
  pyppeteer-install;

# display summary of installed packages and their versions
- conda list

script:
# prevent OpenMPI warning messages
- export OMPI_MCA_btl=^openib
# newer versions of OpenMPI require this
- export OMPI_MCA_rmaps_base_oversubscribe=1
# IPOpt requires this
- export LD_LIBRARY_PATH=/home/travis/ipopt/lib

# make docs first
- cd openmdao/docs;
- if [ "$PETSc" ]; then
    make travis;
  fi

# run the tests from down here to see if it can work without being at top level
# only do coverage on the upload machine (and show skipped tests).
- if [ "$UPLOAD_DOCS" ]; then
    testflo -n 1 openmdao --timeout=120 --show_skipped --coverage  --coverpkg openmdao --cover-omit \*tests/\*  --cover-omit \*devtools/\* --cover-omit \*test_suite/\* --cover-omit \*docs/\* --cover-omit \*code_review/\*;
  else
    testflo -n 1 openmdao --timeout=120 --show_skipped;
  fi

after_success:
# again, only run coverage operations on the upload machine after success.
# strip the site-package path so that links works on coveralls.io
- if [ "$UPLOAD_DOCS" ]; then
    echo " >> Installing forked version of coveralls";
    pip install git+https://github.com/swryan/coveralls-python@work;

    coveralls --rcfile=../../.coveragerc --output=coveralls.json;
    SITE=`python -c 'import site; print(site.getsitepackages()[0])'`;
    sed "s/${SITE//\//\\/}\///g" < coveralls.json > coveralls-upd.json;
    coveralls --upload=coveralls-upd.json;
  fi

deploy:
  provider: script
  skip_cleanup: true
  script:
  # only deploy docs in a build after a PR or merge is accepted
  - if [ "$MASTER_BUILD" ] && [ "$UPLOAD_DOCS" ]; then
      python _utils/upload_doc_version.py;
    fi
  on:
    branch: master
