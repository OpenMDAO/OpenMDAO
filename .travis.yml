branches:
  only:
  - master

group: deprecated-2017Q4

filter_secrets: false

os:
- linux

language: generic

env:
  matrix:
    - PY=2.7 NUMPY=1.12
    - PY=2.7 NUMPY=1.13 PETSc=3.8.1
    - PY=3.6 NUMPY=1.12
    - PY=3.6 NUMPY=1.14 PETSc=3.8.1 UPLOAD_DOCS=1
    - PY=3.7 NUMPY=1.15 PETSc=3.9.1

git:
  depth: 99999

addons:
  apt:
    update: true
    sources:
    - ubuntu-toolchain-r-test
    packages:
    - gfortran
    - libblas-dev
    - liblapack-dev
    - libopenmpi-dev
    - openmpi-bin
    ssh_known_hosts:
    - web543.webfaction.com

cache:
  apt: true
  timeout: 300
  directories:
    - $HOME/.cache/pip
    - $HOME/miniconda

notifications:
  slack:
    secure: Dd+tpZkz48Q47Y+PtdL4b+KAs55PsvWjt9ybhip6xljhA5kVsba9oZS+KsAC8RLWSzVJLOSjz3Cu3MsRym4sTd/g4Pbqyh0ldK2Xnl+n2JOgpPFSXtFuH4Ln3uWB6kYtUK6+aGIC8qhbvEt8tukTBT0RduEmdRyVIZ3oN7YjETPSZXvujeiUFLssfpZW2mqoA/tIgJHFSlySAp6J5694t2Z/p8sHOrK8G/Nm+qlk4xqXHvJ3xablcSBG4BZCrpqmMMdTLXBt2E2K9Rc1P2ZBIrSHVWfSLx+4n79U2385+og7miN1Zuf3gY3YuGKIwnBTtEzTu20905idkr4QdKELCBEcU4azdznwjvUkXWkiFAJII9UELTluSQmZX602zWk4AgJNeHxhN3EbBSMezfYVZjprhlAlwnZZv6t4qAkvuzb7KOA4s679xWzWOBOn1wkynfIF8A66APqssveyz/PvZHSjnHQoLgMU+kwzoX759o0Z/HuRlhCcjv0W9DWxU2bFNi/zVh9YyvR8fG15biGthzOyuf+CHjxohw+J6M+YdR1RIf1g/60nGUPHx4j4SN3kEFPmEDxzZT/f349gvaZGOmKXBi0wH8iY/i9RinM9LJB4t6chj2MkKwUA26bYaVaIO6FYPfE7r+tTG6OXdck4voCs/s4aa9VKEX97yhh0i9g=

before_install:
# Check for existence of files to determine if cache exists
# If the dir doesn't exist, but is slated to be cached later,
# Travis unhelpfully creates it, which then causes "dir already exists"
# errors when you go to actually install the thing, so we must non-intuitively
# delete the file before re-creating it later.
- if [ -d $HOME/miniconda/envs/PY$PY ]; then
    echo "cached miniconda environment found";
    CACHED_ENV=1;
  else
    echo "cached miniconda environment not found";
    rm -rf $HOME/miniconda;
  fi

- if  [ "$TRAVIS_REPO_SLUG" = "OpenMDAO/OpenMDAO" ] && [ "$TRAVIS_PULL_REQUEST" = "false" ]; then
    MASTER_BUILD=1;
  fi

install:
# get key decrypted, placed, chmodded, and added for passwordless access to WebFaction
- if [ "$encrypted_74d70a284b7d_key" ]; then
    openssl aes-256-cbc -K $encrypted_74d70a284b7d_key -iv $encrypted_74d70a284b7d_iv -in travis_deploy_rsa.enc -out /tmp/travis_deploy_rsa -d;
    eval "$(ssh-agent -s)";
    chmod 600 /tmp/travis_deploy_rsa;
    ssh-add /tmp/travis_deploy_rsa;
    echo -e "Host web543.webfaction.com\n\tStrictHostKeyChecking no\n" >> ~/.ssh/config;
  fi

# if we don't have a cached conda environment then build one, otherwise just activate the cached one
- if [ "$CACHED_ENV" ]; then
    echo "Using cached environment..."
    export PATH=$HOME/miniconda/bin:$PATH;
    source $HOME/miniconda/bin/activate PY$PY;
  else
    echo "Building python environment...";
    wget "https://repo.continuum.io/miniconda/Miniconda${PY:0:1}-4.5.11-Linux-x86_64.sh" -O miniconda.sh;
    chmod +x miniconda.sh;
    ./miniconda.sh -b  -p $HOME/miniconda;
    export PATH=$HOME/miniconda/bin:$PATH;

    conda create --yes -n PY$PY python=$PY;
    source $HOME/miniconda/bin/activate PY$PY;

    conda install --yes numpy=$NUMPY scipy>=1.0 cython swig nose sphinx mock;

    pip install --upgrade pip;
    pip install redbaron;
    pip install git+https://github.com/OpenMDAO/testflo.git;
    pip install coverage;
    pip install git+https://github.com/swryan/coveralls-python@work;

    git clone https://github.com/OpenMDAO/pyoptsparse.git;
    cd pyoptsparse;

    if [ "$SNOPT_LOCATION" ] && [ "${PY:0:1}" = "3" ]; then
      cd pyoptsparse/pySNOPT;
      scp -r "$SNOPT_LOCATION" .;
      cd ../..;
    fi

    python setup.py install;
    cd ..;

    if [ "$PETSc" ]; then
      pip install mpi4py petsc4py==$PETSc;
    fi

    conda install --yes matplotlib;
  fi

# install OpenMDAO (Not using -e on purpose here, to catch pkging errors)
- pip install .;

# display summary of installed packages and their versions
- conda list

script:
# make docs first
- cd openmdao/docs;
- if [ "$PETSc" ]; then
    make travis;
  fi

# run the tests from down here to see if it can work without being at top level
# only do coverage on the upload machine.
- if [ "$UPLOAD_DOCS" ]; then
    testflo -n 1 openmdao --coverage  --coverpkg openmdao --cover-omit \*tests/\*  --cover-omit \*devtools/\* --cover-omit \*test_suite/\* --cover-omit \*docs/\*;
  else
    testflo -n 1 --timeout=120 openmdao;
  fi

after_success:
# again, only run coverage operations on the upload machine after success.
- if [ "$UPLOAD_DOCS" ]; then
    coveralls --rcfile=../../.coveragerc --output=coveralls.json;
    sed 's/\/home\/travis\/miniconda\/lib\/python'"$PY"'\/site-packages\///g' < coveralls.json > coveralls-upd.json;
    coveralls --upload=coveralls-upd.json;
  fi

deploy:
  provider: script
  skip_cleanup: true
  script:
  # only deploy docs in a build after a PR or merge is accepted
  - if [ "$MASTER_BUILD" ] && [ "$UPLOAD_DOCS" ]; then
      python _utils/upload_doc_version.py;
    fi
  on:
    branch: master
